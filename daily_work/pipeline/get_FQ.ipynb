{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zfssz8/CNGB_DATA/BGISEQ01/DIPSEQ/DIPSEQT1/P24Z31300N0041_Temp/D2411320126/241216_63_DP8480012554TR_L01_D2411320126001\n",
      "/zfssz8/CNGB_DATA/BGISEQ01/DIPSEQ/DIPSEQT1/P24Z31300N0041_Temp/D2411320127/241216_64_DP8480012555TR_L01_D2411320127001\n",
      "/zfssz8/CNGB_DATA/BGISEQ01/DIPSEQ/DIPSEQT1/P24Z31300N0041_Temp/D2411320128/241216_64_DP8480012555TR_L01_D2411320128001\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "all_dict = []\n",
    "with open('/home/ouyangkang/tmp.tsv', newline='') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        tmp_path = Path(row['Pathway'])\n",
    "        fq_list = [i for i in tmp_path.glob('*.fq.gz')]\n",
    "        if len(fq_list) > 2:\n",
    "            fq_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz']\n",
    "            fq_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz']\n",
    "            fq_1.sort()\n",
    "            fq_2.sort()\n",
    "            write_dict_1 = {'Sample': row['Sample_name'], 'FQ1': fq_1[0], 'FQ2': fq_2[0]}\n",
    "            write_dict_2 = {'Sample': row['Sample_name'], 'FQ1': fq_1[1], 'FQ2': fq_2[1]}\n",
    "            all_dict += [write_dict_1]\n",
    "            all_dict += [write_dict_2]\n",
    "\n",
    "        else:\n",
    "            fq_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz']\n",
    "            fq_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz'] \n",
    "            write_dict = {'Sample': row['Sample_name'], 'FQ1': fq_1, 'FQ2': fq_2}\n",
    "            all_dict += {write_dict}\n",
    "\n",
    "\n",
    "# write a csv file\n",
    "with open('/home/ouyangkang/result.csv', 'w', newline='') as s:\n",
    "\n",
    "    fieldnames = ['Sample', 'FQ1', 'FQ2']\n",
    "    writer = csv.DictWriter(s, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in reader:\n",
    "    print(row['Pathway'])\n",
    "    fq_list = [i for i in Path(row['Pathway']).glob('*.fq.gz')]\n",
    "    print(fq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a python script for batch scRNA submitting in cloud platform\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "input_file = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "\n",
    "all_dict = []\n",
    "with open(input_file, 'r', newline='') as f:\n",
    "    reader = csv.DictReader(f, fieldnames=['Seq_type', 'Sample_name', 'Pathway'], delimiter='\\t')\n",
    "    for row in reader:\n",
    "        if 'cDNA' in row['Seq_type']:\n",
    "            tmp_path = Path(row['Pathway'])\n",
    "            fq_list = [i for i in tmp_path.glob('*.fq.gz')]\n",
    "            if len(fq_list) > 2:\n",
    "                cDNA_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz']\n",
    "                cDNA_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz']\n",
    "                cDNA_1.sort()\n",
    "                cDNA_2.sort()\n",
    "                write_dict_1 = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': cDNA_1[0], 'FQ2': cDNA_2[0]}\n",
    "                write_dict_2 = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': cDNA_1[1], 'FQ2': cDNA_2[1]}\n",
    "                all_dict.append(write_dict_1)\n",
    "                all_dict.append(write_dict_2)\n",
    "            else:\n",
    "                fq_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz'][0]\n",
    "                fq_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz'][0]\n",
    "                write_dict = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': fq_1, 'FQ2': fq_2}\n",
    "                all_dict.append(write_dict)\n",
    "        else:\n",
    "            tmp_path = Path(row['Pathway'])\n",
    "            fq_list = [i for i in tmp_path.glob('*.fq.gz')]\n",
    "            fq_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz'][0]\n",
    "            fq_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz'][0]\n",
    "            write_dict = {'Sample': row['Sample_name'], 'Type': 'Oligo', 'FQ1': fq_1, 'FQ2': fq_2}\n",
    "            all_dict.append(write_dict)\n",
    "\n",
    "\n",
    "result = {}\n",
    "for item in all_dict:\n",
    "    sample = item['Sample']\n",
    "    if sample not in result:\n",
    "        result[sample] = {\n",
    "            'Sample': sample,\n",
    "            'cDNA1': [],\n",
    "            'cDNA2': [],\n",
    "            'Oligo1': [],\n",
    "            'Oligo2': [],\n",
    "            'genomeDir': '',\n",
    "            'Outdir': './',\n",
    "            'expectcells': 10000,\n",
    "            'forcecells': 'False',\n",
    "            'Cpu': 8,\n",
    "            'Mem': 120\n",
    "        }\n",
    "    if item['Type'] == 'Oligo':\n",
    "        result[sample]['Oligo1'].extend(map(str, [item.get('FQ1', '')]))\n",
    "        result[sample]['Oligo2'].extend(map(str, [item.get('FQ2', '')]))\n",
    "    elif item['Type'] == 'cDNA':\n",
    "        result[sample]['cDNA1'].extend(map(str, [item.get('FQ1', '')]))\n",
    "        result[sample]['cDNA2'].extend(map(str, [item.get('FQ2', '')]))\n",
    "\n",
    "\n",
    "# 写入输出文件\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    fieldnames = ['Sample', 'Oligo1', 'Oligo2', 'cDNA1', 'cDNA2', 'genomeDir', 'Outdir', 'expectcells', 'forcecells', 'Cpu', 'Mem']\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "    for sample, data in result.items():\n",
    "        max_row = max(len(data['cDNA1']), len(data['Oligo1']))\n",
    "        for i in range(max_row):\n",
    "            cDNA_1 = data['cDNA1'][i]\n",
    "            cDNA_2 = data['cDNA2'][i]\n",
    "            oligo_1 = data['Oligo1'][i] if i < len(data['Oligo1']) else None\n",
    "            oligo_2 = data['Oligo2'][i] if i < len(data['Oligo2']) else None\n",
    "            genomeDir = data['genomeDir']\n",
    "            outDir = data['Outdir']\n",
    "            expect_cell = data['expectcells']\n",
    "            force_cell = data['forcecells']\n",
    "            cpu = data['Cpu']\n",
    "            mem = data['Mem']\n",
    "            writer.writerow([sample, oligo_1, oligo_2, cDNA_1, cDNA_2, genomeDir, outDir, expect_cell, force_cell, cpu, mem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "file_path = Path('/mnt/c')\n",
    "\n",
    "print(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "input_file = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "\n",
    "# 读取输入文件并解析数据\n",
    "all_dict = []\n",
    "with open(input_file, 'r', newline='') as f:\n",
    "    reader = csv.DictReader(f, fieldnames=['Seq_type', 'Sample_name', 'Pathway'], delimiter='\\t')\n",
    "    for row in reader:\n",
    "        tmp_path = Path(row['Pathway'])\n",
    "        fq_list = [i for i in tmp_path.glob('*.fq.gz')]\n",
    "        fq_1 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '1.fq.gz']\n",
    "        fq_2 = [i for i in fq_list if i.parts[-1].split('_')[-1] == '2.fq.gz']\n",
    "        \n",
    "        if 'cDNA' in row['Seq_type']:\n",
    "            if len(fq_list) > 2:\n",
    "                fq_1.sort()\n",
    "                fq_2.sort()\n",
    "                write_dict_1 = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': fq_1[0], 'FQ2': fq_2[0]}\n",
    "                write_dict_2 = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': fq_1[1], 'FQ2': fq_2[1]}\n",
    "                all_dict.append(write_dict_1)\n",
    "                all_dict.append(write_dict_2)\n",
    "            else:\n",
    "                write_dict = {'Sample': row['Sample_name'], 'Type': 'cDNA', 'FQ1': fq_1[0], 'FQ2': fq_2[0]}\n",
    "                all_dict.append(write_dict)\n",
    "        else:\n",
    "            write_dict = {'Sample': row['Sample_name'], 'Type': 'Oligo', 'FQ1': fq_1[0], 'FQ2': fq_2[0]}\n",
    "            all_dict.append(write_dict)\n",
    "\n",
    "# 按样本分组并合并数据\n",
    "from collections import defaultdict\n",
    "\n",
    "merged_data = defaultdict(lambda: {'Oligo1': None, 'Oligo2': None, 'cDNA1': None, 'cDNA2': None})\n",
    "for entry in all_dict:\n",
    "    sample = entry['Sample']\n",
    "    if entry['Type'] == 'Oligo':\n",
    "        merged_data[sample]['Oligo1'] = entry['FQ1']\n",
    "        merged_data[sample]['Oligo2'] = entry['FQ2']\n",
    "    elif entry['Type'] == 'cDNA':\n",
    "        if not merged_data[sample]['cDNA1']:\n",
    "            merged_data[sample]['cDNA1'] = entry['FQ1']\n",
    "            merged_data[sample]['cDNA2'] = entry['FQ2']\n",
    "        else:\n",
    "            # 创建新行\n",
    "            new_row = {'Sample': sample, 'Oligo1': None, 'Oligo2': None, 'cDNA1': entry['FQ1'], 'cDNA2': entry['FQ2']}\n",
    "            merged_data[sample] = new_row\n",
    "\n",
    "# 写入输出文件\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    fieldnames = ['Sample', 'Oligo1', 'Oligo2', 'cDNA1', 'cDNA2']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    for sample, data in merged_data.items():\n",
    "        writer.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
